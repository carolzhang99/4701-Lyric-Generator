{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Prac Artists Analysis",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6LGsCfz6GPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "005030ac-bd3b-45b0-ddc8-08c5057469aa"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
        "\n",
        "data = pd.read_csv('my_billboard.csv', engine='python', error_bad_lines=False)\n",
        "data = data[data['spotify_link'].notnull()]\n",
        "data = data[data['lyrics'].notnull()]\n",
        "type(data['artist'].unique())\n",
        "artists = list(data['artist'].unique())[:500]\n",
        "my_artists = []\n",
        "for art in artists:\n",
        "  if '&' not in art and ',' not in art and '+':\n",
        "    my_artists.append(art)\n",
        "\n",
        "artists = my_artists[:100]\n",
        "artists.remove('Chris Stapleton')\n",
        "artists.remove('Alice Merton')\n",
        "artists.remove('Kenny Chesney')\n",
        "artists.remove('Cole Swindell')\n",
        "\n",
        "artists.append('Rihanna')\n",
        "artists.append('Pitbull')\n",
        "artists.append('Katy Perry')\n",
        "artists.append('Drake')\n",
        "print(artists)\n",
        "\n",
        "data = data[data['artist'].isin(artists)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Juice WRLD', 'Kanye West', 'Selena Gomez', 'Cardi B', 'Luke Combs', 'Post Malone', 'Ella Mai', 'The Weeknd', 'Nicki Minaj', 'KIDS SEE GHOSTS', 'Taylor Swift', 'Daddy Yankee', 'Lil Pump', 'BTS', 'Drake', 'Kane Brown', 'Lauv', 'Blake Shelton', 'Jake Owen', 'Dua Lipa', 'Shawn Mendes', 'Famous Dex', 'J. Cole', 'Brett Young', 'Bazzi', 'Camila Cabello', 'Ariana Grande', 'YoungBoy Never Broke Again', 'Ed Sheeran', 'Rich The Kid', 'XXXTENTACION', 'Florida Georgia Line', 'Becky G + Natti Natasha', 'Jordan Davis', 'Foster The People', 'Dan + Shay', 'Childish Gambino', 'Maroon 5', 'Imagine Dragons', 'Dierks Bentley', 'Nicky Jam x J Balvin', 'Jason Aldean', '5 Seconds Of Summer', 'Bad Wolves', 'Lil Skies', 'Darius Rucker', 'Panic! At The Disco', 'Pusha T', 'Luke Bryan', 'Kevin Gates', 'Backstreet Boys', 'Sam Hunt', 'Kris Wu', 'Meghan Trainor', 'Pharrell Williams x Camila Cabello', 'Lil Baby', 'Carrie Underwood', 'Migos', 'Tank', 'Mason Ramsey', 'Portugal. The Man', 'NF', 'Brett Eldredge', 'Avicii', 'Halsey', '6ix9ine', 'SZA', 'Scotty McCreery', \"Derez De'Shon\", 'Zayn', 'Thomas Rhett', 'High Valley', 'Devin Dawson', 'Queen Naija', 'Demi Lovato', 'P!nk', 'H.E.R.', 'Chris Brown', 'Old Dominion', 'Logic', 'Lil Xan', 'Blac Youngsta', 'YBN Nahmir', 'The Chainsmokers', 'Charlie Puth', 'Khalid', 'SOB X RBE', 'Janelle Monae', 'Plies', 'Walker Hayes', 'Russell Dickerson', 'Keith Urban', 'Kelsea Ballerini', 'WALK THE MOON', 'Sam Smith', 'Kendrick Lamar', 'Rihanna', 'Pitbull', 'Katy Perry', 'Drake']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrnBGdeY61pt"
      },
      "source": [
        "import numpy as np\n",
        "n_docs = data.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQjPl2eA7nk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca5c72ff-42e5-4c1a-8926-8dd7cde53df6"
      },
      "source": [
        "print(n_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnq0ln7vJ5WP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8043552d-69e2-4efd-934e-f32b45c0bea4"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hunP8_m6F9Xj"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "sw = stopwords.words('english')\n",
        "\n",
        "def termify():\n",
        "  all_words = {}\n",
        "\n",
        "  for row in data.iterrows():\n",
        "      row = pd.Series.to_dict(row[1])\n",
        "      for word in row['lyrics'].split():\n",
        "          if '\\n' not in word:\n",
        "            if word not in all_words:\n",
        "                all_words[word] = 1\n",
        "            else:\n",
        "                all_words[word] +=1\n",
        "\n",
        "  keys = all_words.keys()\n",
        "  n_words = len(keys)\n",
        "\n",
        "  key_list = list(all_words.keys())\n",
        "  key_list.sort()\n",
        "\n",
        "  plots = []\n",
        "  for row in data.iterrows():\n",
        "      plot = pd.Series.to_dict(row[1])['lyrics']\n",
        "      plots.append(plot)\n",
        "\n",
        "  tfidf_vec = TfidfVectorizer(max_df = 0.8, min_df = 10, max_features = 5000, stop_words = 'english', norm = 'l2')\n",
        "  doc_by_vocab = tfidf_vec.fit_transform(plots).toarray()\n",
        "  index_to_vocab = {i:v for i, v in enumerate(tfidf_vec.get_feature_names())}\n",
        "\n",
        "  tf_idf = np.transpose(doc_by_vocab)\n",
        "  av_tfidf = {}\n",
        "  for i in range(len(index_to_vocab)):\n",
        "      av_tfidf[index_to_vocab[i]] = np.sum(tf_idf[i])/n_docs\n",
        "\n",
        "  l=list(av_tfidf.items())\n",
        "  new = sorted(l, key=lambda x: x[1], reverse=True)\n",
        "  #print(new)\n",
        "  terms = [tup[0] for tup in new]\n",
        "  top_terms = [x for x in terms if x not in sw][:300]\n",
        "  return top_terms\n",
        "\n",
        "my_terms = termify()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ_YdkdTYzhc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3df3f4-1241-456a-982c-cac4a4876de2"
      },
      "source": [
        "print(my_terms)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['yeah', 'like', 'know', 'love', 'got', 'baby', 'error', 'lyrics', 'oh', 'let', 'nigga', 'ooh', 'way', 'want', 'niggas', 'make', 'time', 'bitch', 'shit', 'fuck', 'cause', 'say', 'girl', 'uh', 'feel', 'man', 'gang', 'wanna', 'em', 'right', 'heart', 'life', 'gon', 'tell', 'boy', 'come', 'need', 'mind', 'think', 'said', 'money', 'better', 'away', 'gonna', 'look', 'head', 'gotta', 'new', 'bad', 'crazy', 'ayy', 'yo', 'everybody', 'night', 'really', 'good', 'ya', 'believe', 'whip', 'alright', 'woo', 'huh', 'stay', 'lost', 'god', 'things', 'long', 'tryna', 'try', 'tonight', 'hard', 'pull', 'break', 'face', 'hey', 'pain', 'world', 'gave', 'die', 'turn', 'bout', 'stop', 'wait', 'hit', 'body', 'damn', 'lot', 'eyes', 'guess', 'song', 'care', 'high', 'black', 'days', 'movin', 'little', 'somebody', 'leave', 'lose', 'play', 'went', 'sorry', 'babe', 'hear', 'lord', 'best', 'talk', 'bitches', 'people', 'big', 'going', 'day', 'doin', 'walk', 'hold', 'count', 'young', 'thing', 'took', 'cut', 'run', 'check', 'livin', 'knew', 'fall', 'help', 'gone', 'wish', 'real', 'close', 'watch', 'goin', 'friends', 'okay', 'times', 'free', 'soul', 'thought', 'broken', 'remember', 'wake', 'dead', 'told', 'mama', 'forget', 'beat', 'feeling', 'save', 'broke', 'hope', 'pop', 'bet', 'lil', 'used', 'fly', 'sleep', 'trust', 'mean', 'rock', 'matter', 'phone', 'bag', 'ride', 'woah', 'work', 'thousand', 'easy', 'drink', 'live', 'word', 'light', 'looking', 'brain', 'pussy', 'hate', 'hot', 'open', 'sure', 'red', 'fast', 'bed', 'shots', 'straight', 'catch', 'runnin', 'home', 'end', 'stand', 'wrong', 'wrist', 'til', 'hand', 'old', 'block', 'mad', 'ice', 'came', 'drop', 'fuckin', 'forever', 'ass', 'comin', 'gettin', 'left', 'room', 'party', 'talkin', 'spot', 'lookin', 'heard', 'understand', 'bentley', 'mouth', 'change', 'door', 'plug', 'girls', 'smoke', 'club', 'game', 'years', 'seen', 'business', 'talking', 'met', 'city', 'miss', 'yes', 'hands', 'rap', 'gucci', 'start', 'bands', 'hoes', 'blow', 'shoot', 'bring', 'hang', 'making', 'friend', 'bust', 'case', 'place', 'taking', 'floor', 'cool', 'daddy', 'true', 'getting', 'pick', 'saying', 'lay', 'drive', 'diamonds', 'truth', 'roll', 'fucked', 'inside', 'watchin', 'eat', 'sound', 'kiss', 'swear', 'low', 'box', 'caught', 'minute', 'water', 'gets', 'mirror', 'shot', 'buy', 'chain', 'dope', 'trying', 'sit', 'ho', 'dream', 'send', 'goes', 'car', 'bought', 'music', 'words', 'cold', 'momma', 'dick', 'act', 'house', 'fight', 'worth', 'use', 'kill', 'family', 'dance', 'neck', 'flex', 'probably', 'clothes', 'hell']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5K2RF1lQ1Fe"
      },
      "source": [
        "def docufy_csv_to_features(top_terms):\n",
        "  all_docs = []\n",
        "  all_X = []\n",
        "  all_y = []\n",
        "\n",
        "  for row in data.iterrows():\n",
        "      row = pd.Series.to_dict(row[1])\n",
        "      lyr = row['lyrics'].split()\n",
        "      document_words = set(lyr)\n",
        "      features = {}\n",
        "      count = 0\n",
        "      for word in top_terms:\n",
        "          features[word] = (word in document_words)\n",
        "            \n",
        "      all_docs.append((features, row['artist']))\n",
        "      all_X.append(features)\n",
        "      all_y.append(row['artist'])\n",
        "\n",
        "  return (all_docs, all_X, all_y)\n",
        "\n",
        "test_all_docs = docufy_csv_to_features(my_terms)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH6s41c1TRQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efec6dcd-3043-4990-82ec-34a91a555569"
      },
      "source": [
        "print(test_all_docs[0][1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'yeah': False, 'like': True, 'know': False, 'love': True, 'got': True, 'baby': False, 'error': False, 'lyrics': False, 'oh': False, 'let': True, 'nigga': False, 'ooh': False, 'way': False, 'want': True, 'niggas': False, 'make': True, 'time': True, 'bitch': True, 'shit': True, 'fuck': True, 'cause': False, 'say': True, 'girl': False, 'uh': False, 'feel': False, 'man': False, 'gang': False, 'wanna': False, 'em': False, 'right': False, 'heart': False, 'life': False, 'gon': False, 'tell': False, 'boy': False, 'come': False, 'need': False, 'mind': True, 'think': True, 'said': False, 'money': False, 'better': False, 'away': False, 'gonna': True, 'look': False, 'head': False, 'gotta': True, 'new': False, 'bad': False, 'crazy': True, 'ayy': False, 'yo': False, 'everybody': False, 'night': False, 'really': False, 'good': False, 'ya': False, 'believe': False, 'whip': False, 'alright': False, 'woo': False, 'huh': False, 'stay': False, 'lost': False, 'god': False, 'things': True, 'long': False, 'tryna': False, 'try': False, 'tonight': False, 'hard': False, 'pull': True, 'break': False, 'face': False, 'hey': False, 'pain': False, 'world': False, 'gave': False, 'die': False, 'turn': False, 'bout': False, 'stop': False, 'wait': False, 'hit': True, 'body': False, 'damn': False, 'lot': False, 'eyes': False, 'guess': False, 'song': False, 'care': False, 'high': False, 'black': False, 'days': False, 'movin': False, 'little': False, 'somebody': False, 'leave': True, 'lose': True, 'play': False, 'went': False, 'sorry': False, 'babe': False, 'hear': False, 'lord': False, 'best': False, 'talk': False, 'bitches': False, 'people': False, 'big': True, 'going': False, 'day': False, 'doin': False, 'walk': False, 'hold': True, 'count': False, 'young': False, 'thing': False, 'took': False, 'cut': False, 'run': False, 'check': False, 'livin': False, 'knew': False, 'fall': False, 'help': False, 'gone': False, 'wish': False, 'real': False, 'close': False, 'watch': False, 'goin': False, 'friends': False, 'okay': False, 'times': False, 'free': False, 'soul': False, 'thought': False, 'broken': False, 'remember': False, 'wake': False, 'dead': False, 'told': False, 'mama': False, 'forget': False, 'beat': False, 'feeling': False, 'save': False, 'broke': False, 'hope': False, 'pop': False, 'bet': False, 'lil': False, 'used': False, 'fly': False, 'sleep': False, 'trust': False, 'mean': False, 'rock': False, 'matter': False, 'phone': False, 'bag': False, 'ride': False, 'woah': False, 'work': False, 'thousand': False, 'easy': False, 'drink': False, 'live': False, 'word': False, 'light': False, 'looking': False, 'brain': False, 'pussy': True, 'hate': False, 'hot': False, 'open': False, 'sure': False, 'red': False, 'fast': False, 'bed': False, 'shots': False, 'straight': False, 'catch': False, 'runnin': False, 'home': False, 'end': False, 'stand': False, 'wrong': False, 'wrist': False, 'til': False, 'hand': False, 'old': False, 'block': False, 'mad': False, 'ice': False, 'came': False, 'drop': False, 'fuckin': False, 'forever': False, 'ass': True, 'comin': False, 'gettin': False, 'left': False, 'room': False, 'party': False, 'talkin': False, 'spot': False, 'lookin': False, 'heard': False, 'understand': False, 'bentley': False, 'mouth': False, 'change': False, 'door': False, 'plug': False, 'girls': True, 'smoke': False, 'club': False, 'game': False, 'years': False, 'seen': False, 'business': False, 'talking': False, 'met': False, 'city': False, 'miss': False, 'yes': False, 'hands': False, 'rap': False, 'gucci': False, 'start': False, 'bands': False, 'hoes': False, 'blow': False, 'shoot': False, 'bring': False, 'hang': False, 'making': False, 'friend': False, 'bust': False, 'case': False, 'place': False, 'taking': True, 'floor': False, 'cool': False, 'daddy': False, 'true': False, 'getting': False, 'pick': False, 'saying': False, 'lay': False, 'drive': False, 'diamonds': False, 'truth': False, 'roll': False, 'fucked': False, 'inside': False, 'watchin': False, 'eat': False, 'sound': False, 'kiss': False, 'swear': False, 'low': False, 'box': False, 'caught': False, 'minute': False, 'water': False, 'gets': False, 'mirror': False, 'shot': False, 'buy': False, 'chain': False, 'dope': False, 'trying': False, 'sit': False, 'ho': False, 'dream': False, 'send': False, 'goes': False, 'car': False, 'bought': False, 'music': False, 'words': False, 'cold': False, 'momma': False, 'dick': False, 'act': False, 'house': False, 'fight': False, 'worth': False, 'use': False, 'kill': False, 'family': False, 'dance': False, 'neck': False, 'flex': False, 'probably': False, 'clothes': False, 'hell': False}, 'Kanye West')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWhtlnEgP1eu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456ea412-3f11-4da5-9123-82952af5e0b0"
      },
      "source": [
        "test_ratio = 0.1\n",
        "cutoff = int(len(test_all_docs[0]) * test_ratio)\n",
        "train_set, test_set = test_all_docs[0][cutoff:], test_all_docs[0][:cutoff]\n",
        "classifier1 = nltk.NaiveBayesClassifier.train(train_set)\n",
        "classifier2 = SklearnClassifier(BernoulliNB()).train(train_set)\n",
        "print('Achieved {0:.2f}% accuracy against training set'.format(nltk.classify.accuracy(classifier1, train_set)*100))\n",
        "print('Achieved {0:.2f}% accuracy against test set'.format(nltk.classify.accuracy(classifier1, test_set)*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Achieved 86.94% accuracy against training set\n",
            "Achieved 72.39% accuracy against test set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiTli0LdHZBG"
      },
      "source": [
        "xtest = test_all_docs[1][:cutoff]\n",
        "predicted = []\n",
        "for entry in xtest:\n",
        "  predicted.append(classifier2.classify(entry))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UG9lStk-HTsO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b8bce8-f06a-4434-e268-94f2e75d5218"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "actual = test_all_docs[2][:cutoff]\n",
        "results = confusion_matrix(actual, predicted) \n",
        "  \n",
        "print('Confusion Matrix :')\n",
        "print(results) \n",
        "print('Report : ')\n",
        "print(classification_report(actual, predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix :\n",
            "[[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 3 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "Report : \n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "            BTS       0.00      0.00      0.00         1\n",
            "        Cardi B       0.00      0.00      0.00         1\n",
            "   Daddy Yankee       0.00      0.00      0.00         1\n",
            "          Drake       0.00      0.00      0.00         1\n",
            "       Ella Mai       0.00      0.00      0.00         1\n",
            "        J. Cole       0.00      0.00      0.00         0\n",
            "     Juice WRLD       0.00      0.00      0.00         1\n",
            "KIDS SEE GHOSTS       0.00      0.00      0.00         4\n",
            "     Kane Brown       0.00      0.00      0.00         1\n",
            "     Kanye West       0.00      0.00      0.00         1\n",
            "       Lil Pump       0.00      0.00      0.00         1\n",
            "     Luke Combs       0.00      0.00      0.00         1\n",
            "    Nicki Minaj       0.00      0.00      0.00         1\n",
            "    Post Malone       0.11      1.00      0.20         1\n",
            "   Selena Gomez       0.00      0.00      0.00         1\n",
            "   Taylor Swift       0.00      0.00      0.00         1\n",
            "     The Weeknd       0.00      0.00      0.00         1\n",
            "\n",
            "       accuracy                           0.05        19\n",
            "      macro avg       0.01      0.06      0.01        19\n",
            "   weighted avg       0.01      0.05      0.01        19\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEucr6uzdI9T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a59c5a10-e603-48ae-c066-48538e23ad9a"
      },
      "source": [
        "classifier1.show_most_informative_features(25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "                   gotta = True            Drake : Post M =      8.2 : 1.0\n",
            "                    head = True               NF : Post M =      7.8 : 1.0\n",
            "                    talk = True               NF : Post M =      7.8 : 1.0\n",
            "                     run = True           Lil Ba : Post M =      7.8 : 1.0\n",
            "                    long = True           KIDS S : Post M =      7.8 : 1.0\n",
            "                      oh = True           KIDS S : Post M =      7.8 : 1.0\n",
            "                    mind = True           Shawn  : Post M =      7.8 : 1.0\n",
            "                  things = True               NF : Post M =      7.8 : 1.0\n",
            "                   wrong = True               NF : Post M =      7.8 : 1.0\n",
            "                   heart = True           Charli : Post M =      7.8 : 1.0\n",
            "                    game = True           Kevin  : Post M =      7.8 : 1.0\n",
            "                 friends = True           Luke B : Post M =      7.8 : 1.0\n",
            "                    came = True           Russel : Post M =      7.0 : 1.0\n",
            "                   trust = True           WALK T : Post M =      7.0 : 1.0\n",
            "                     lot = True           Lil Pu : Post M =      7.0 : 1.0\n",
            "                    room = True           Walker : Post M =      7.0 : 1.0\n",
            "                     mad = True           Devin  : Post M =      7.0 : 1.0\n",
            "                    mean = True           Sam Sm : Post M =      7.0 : 1.0\n",
            "                   world = True           Kelsea : Post M =      7.0 : 1.0\n",
            "                    need = True            Plies : Post M =      7.0 : 1.0\n",
            "                   words = True           Khalid : Post M =      7.0 : 1.0\n",
            "                  bought = True           Lil Pu : Post M =      7.0 : 1.0\n",
            "                    true = True           Sam Sm : Post M =      7.0 : 1.0\n",
            "                   start = True           Walker : Post M =      7.0 : 1.0\n",
            "                   light = True           Blac Y : Post M =      7.0 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7Hs5nG-OcRG"
      },
      "source": [
        "#ADD UR OWN WORDS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UbMbX9GkWnl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "847f67de-f409-4cd2-a61a-ae854206e906"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "X_train = test_all_docs[1][cutoff:]\n",
        "y_train = test_all_docs[2][cutoff:]\n",
        "X_test = test_all_docs[1][:cutoff]\n",
        "y_test = test_all_docs[2][:cutoff]\n",
        "knn = KNeighborsClassifier(n_neighbors = 7).fit([X_train], [y_train]) \n",
        "  \n",
        "# accuracy on X_test \n",
        "accuracy = knn.score([X_test], [y_test]) \n",
        "print(accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-cd440033575f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_all_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_all_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# accuracy on X_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1124\u001b[0m         \"\"\"\n\u001b[1;32m   1125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict'"
          ]
        }
      ]
    }
  ]
}